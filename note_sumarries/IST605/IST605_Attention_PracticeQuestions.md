# IST605: Human Information Processing — Attention Practice Questions

**Distribution:** 25% Easy (5) | 40% Normal (8) | 35% Hard (7) — 20 questions total  
**Types:** MCQ, structural (short answer), and complete (paragraph). All with answers and explanations.  
**Note:** MCQ answers are randomly distributed across A, B, C, D to avoid bias.

---

## EASY (25% — 5 questions)

### E1. MCQ
**Which of the following best describes automaticity in attention?**
A) The ability to process multiple tasks simultaneously without any effort  
B) A significant reduction in the perceived difficulty of a task with practice, often requiring less cognitive resources  
C) The complete elimination of all cognitive resources needed for a task  
D) The process of focusing attention on a single object  

<details>
<summary><b>Answer</b></summary>

**B)** A significant reduction in the perceived difficulty of a task with practice, often requiring less cognitive resources

**Explanation:** Automaticity refers to the reduction in attentional demands that comes with practice. While the most stringent view says automatic processes require no cognitive resources, the more common understanding is that there is a significant reduction in perceived difficulty. Examples include driving a car or performing well-practiced skills where conscious monitoring is no longer necessary.
</details>

---

### E2. Structural
**What are the two types of sensory stores mentioned in attention research, and which sensory modality does each correspond to?**

<details>
<summary><b>Answer</b></summary>

**Iconic memory** (visual sensory store) and **echoic memory** (auditory sensory store).

**Explanation:** Sensory stores record sensory information automatically but decay after a brief period. They have very high capacity. Iconic memory handles visual information, while echoic memory handles auditory information.
</details>

---

### E3. MCQ
**In a dichotic listening experiment, when participants are told to attend to messages in one ear, what typically happens to information in the unattended ear?**
A) They are aware that a voice was present but cannot report much beyond that, not even the language  
B) They can fully recall and report all details from the unattended ear  
C) They completely suppress all information from the unattended ear  
D) They process the unattended ear's information better than the attended ear  

<details>
<summary><b>Answer</b></summary>

**A)** They are aware that a voice was present but cannot report much beyond that, not even the language

**Explanation:** Dichotic listening experiments show that focusing attention on one channel does not completely suppress other input. Participants are aware that a voice was present in the unattended ear but cannot report details like the language or content. This demonstrates the limits of selective attention.
</details>

---

### E4. Structural
**Name three of the five main functions of attention.**

<details>
<summary><b>Answer</b></summary>

Any three of: Focusing, Perceptual Enhancement, Binding, Sustaining Behaviour, Action Selection.

**Explanation:** The five functions are: (1) Focusing—limiting items processed; (2) Perceptual Enhancement—increasing stimulus gain; (3) Binding—combining features into coherent objects; (4) Sustaining Behaviour—maintaining action despite distractions; (5) Action Selection—choosing and ordering actions.
</details>

---

### E5. MCQ
**According to capacity theories of attention, why can auditory and visual tasks often be performed together more easily than two visual tasks?**
A) Visual tasks require more resources than auditory tasks  
B) Auditory information is processed faster than visual information  
C) Visual tasks interfere with each other more than auditory tasks do  
D) There are separate resource pools for different modalities (e.g., visual vs auditory)  

<details>
<summary><b>Answer</b></summary>

**D)** There are separate resource pools for different modalities (e.g., visual vs auditory)

**Explanation:** Capacity theories propose that we have limited attentional resources distributed across multiple resource pools. Evidence suggests separate pools for visual and auditory tasks. When tasks draw from different pools, they interfere less with each other, which is why visual and auditory tasks can be performed together more easily than two tasks from the same modality.
</details>

---

## NORMAL (40% — 8 questions)

### N1. MCQ
**What is the key difference between consistent mapping and varied mapping in visual search tasks?**
A) In consistent mapping, targets never appear as distractors; in varied mapping, targets and distractors overlap  
B) Consistent mapping uses letters while varied mapping uses numbers  
C) Consistent mapping is easier initially but becomes harder with practice  
D) Varied mapping requires less attention than consistent mapping  

<details>
<summary><b>Answer</b></summary>

**A)** In consistent mapping, targets never appear as distractors; in varied mapping, targets and distractors overlap

**Explanation:** In consistent mapping, if an item is a target on one trial, it never appears as a distractor (e.g., detecting a letter among digits). In varied mapping, the target and distractor sets overlap (e.g., detecting a letter among other letters). This structural difference affects how automatic processing develops with practice.
</details>

---

### N2. Complete
**Explain how perceptual enhancement works as a function of attention, and describe when it is effective versus when it fails.**

<details>
<summary><b>Answer</b></summary>

**Perceptual enhancement** increases the gain (strength) of a stimulus in the environment, functioning like turning up the volume on a car radio. It makes perceptual input stronger by amplifying the signal. Perceptual enhancement is **effective when the signal is clear**—turning up the volume helps drown out external noise (like car tires, other vehicles). However, it **fails when the signal itself contains noise** (like static in the radio signal)—in this case, turning up the volume amplifies both the signal and the noise, making perceptual enhancement ineffective. Evidence suggests attention helps by reducing external noise rather than amplifying it along with the signal, such as by increasing contrast between objects and backgrounds or filtering out external noise.

**Explanation:** Perceptual enhancement is attention as concentration—making stimuli stronger. Its effectiveness depends on signal quality, not just amplification.
</details>

---

### N3. MCQ
**In Broadbent's bottleneck theory of attention, the selective filter:**
A) Processes all information completely before filtering  
B) Can use both physical characteristics and meaning to filter stimuli  
C) Is flexible and can shift attention, but can only use lower-level characteristics (like loudness), not meaning  
D) Operates after stimuli have been recognized and placed in short-term memory  

<details>
<summary><b>Answer</b></summary>

**C)** Is flexible and can shift attention, but can only use lower-level characteristics (like loudness), not meaning

**Explanation:** Broadbent's filter is flexible (can shift to different conversations) but operates early in processing, using only physical/auditory characteristics (pitch, loudness, speech vs non-speech) rather than semantic meaning. This is why it's called an early selection theory. Later improvements to the theory added stages that check for high-priority messages (like one's name) using meaning.
</details>

---

### N4. Structural
**What are the three stages in the improved version of Broadbent's bottleneck theory, and what happens at each stage?**

<details>
<summary><b>Answer</b></summary>

**Stage 1:** Incoming stimuli are analyzed for physical characteristics (pitch, speech vs non-speech). Decisions or responses can be made at this stage (e.g., determining who is speaking).

**Stage 2:** Stimuli are checked against a permanent memory list of high-priority messages (danger signals, vocal patterns of one's name). Such stimuli are attended to at this stage.

**Stage 3:** Stimuli not selected at Stage 2 are matched against current priorities. High-priority signals (e.g., matching conversation partner's voice) are moved up for further processing (comprehension), while low-priority signals are ignored.

**Explanation:** The improved model addresses the limitation that people notice their names in unattended channels by adding stages that check for meaning and priority.
</details>

---

### N5. MCQ
**The feature integration theory of attention proposes that:**
A) Features and objects are processed simultaneously from the start  
B) Features are registered early and automatically in parallel, while objects are identified separately at a later focused attention stage  
C) All features require focused attention to be detected  
D) Binding occurs automatically without attention  

<details>
<summary><b>Answer</b></summary>

**B)** Features are registered early and automatically in parallel, while objects are identified separately at a later focused attention stage

**Explanation:** Feature integration theory has two stages: (1) Pre-attentive stage—different brain parts automatically gather basic features (colours, shape, movement) in parallel; (2) Focused attention stage—features are combined to perceive whole objects, requiring attention and occurring within a "master map of locations."
</details>

---

### N6. Complete
**Describe what happens in a visual search task when searching for a single feature versus a conjunction of features. What does this tell us about attention and binding?**

<details>
<summary><b>Answer</b></summary>

In a **single feature search** (e.g., finding a red T among blue letters), search time does not increase with display size—the task is easy and efficient. This suggests that focusing on a single dimension (like colour) allows easy distinction between values (red vs blue) without needing to bind features together.

In a **conjunction search** (e.g., finding a red T among red Ls and blue Ts), search time increases with display size—the task is difficult. This occurs because the target requires a conjunction of properties (both red AND T), meaning features must be bound together to identify the object.

This pattern indicates that **binding requires attention**. Single features can be detected pre-attentively, but combining features into coherent objects (binding) occurs at the focused attention stage, which is why conjunction searches are slower and scale with display size.

**Explanation:** Visual search tasks provide evidence for feature integration theory: features are detected automatically, but binding them into objects requires focused attention.
</details>

---

### N7. MCQ
**Why might attention be useful even if we could process all environmental information?**
A) Because attention improves memory storage  
B) Because attention increases the speed of perception  
C) Because attention is required for all cognitive processes  
D) Because our action systems are limited—we can only perform a limited number of actions at once  

<details>
<summary><b>Answer</b></summary>

**D)** Because our action systems are limited—we can only perform a limited number of actions at once

**Explanation:** Even if we could process all information, we are limited by what we can do: we have only two arms and legs, can only move in one direction, and can only say one word at a time. Attention transforms parallel-processed information into a form that facilitates action by selecting and ordering actions. This is the "action selection" function of attention.
</details>

---

### N8. Structural
**What is the difference between early selection and late selection theories of attention?**

<details>
<summary><b>Answer</b></summary>

**Early selection theories** (like Broadbent's) propose that filtering occurs early in processing, before stimuli are fully recognized or their meaning is processed. The filter uses physical characteristics (e.g., pitch, loudness) to select which channels receive further processing.

**Late selection theories** propose that bottlenecks occur later, after stimuli have been recognized and placed in short-term memory. Information that is not rehearsed or elaborated is likely to be forgotten, suggesting the limit occurs at a later stage.

**Explanation:** The distinction is about when in the processing stream the attentional limit occurs—early (before recognition) versus late (after recognition, in memory).
</details>

---

## HARD (35% — 7 questions)

### H1. MCQ
**In Sternberg's visual search task, reaction time increases by approximately 35–40 ms per item. With consistent mapping practice, what happens to this per-item search time?**
A) It increases even more because more items require more attention  
B) It remains constant at 35–40 ms per item  
C) It becomes substantially lower, indicating more automatic processing  
D) It decreases slightly but still increases linearly with display size  

<details>
<summary><b>Answer</b></summary>

**C)** It becomes substantially lower, indicating more automatic processing

**Explanation:** With consistent mapping (where targets never appear as distractors), practice leads to automatic processing. While reaction time decreases overall, the key finding is that the per-item search time becomes substantially lower—the task becomes more efficient per item. In contrast, varied mapping shows lower overall reaction time but the per-item time still increases by a constant amount (like Sternberg's original finding), indicating less automaticity.
</details>

---

### H2. Complete
**Compare and contrast bottleneck theories and capacity theories of attention. How do they explain interference between tasks differently?**

<details>
<summary><b>Answer</b></summary>

**Bottleneck theories** assume that all inputs are processed completely up to a certain stage, after which only attended channels receive further processing. The bottleneck is structural—like a filter that can only let certain information through. Interference occurs because the bottleneck cannot process multiple channels simultaneously (e.g., cannot shift back and forth fast enough to follow two conversations).

**Capacity theories** assume that information processing requires cognitive resources from a limited pool. Resources are depleted as information is processed. Interference occurs when tasks draw from the same resource pool—if two tasks need more resources than available, they compete. However, tasks that draw from different pools (e.g., visual vs auditory) can be performed together more easily.

**Key difference:** Bottleneck theories focus on structural limits (what can be processed), while capacity theories focus on resource allocation (how much processing capacity is available and how it's distributed). Capacity theories also allow for flexible resource allocation—if one task is more important, resources can be devoted to it at the expense of another.

**Explanation:** Both explain attentional limits but through different mechanisms: structural bottlenecks versus limited resources that can be allocated flexibly.
</details>

---

### H3. MCQ
**According to ideal observer analysis, if there is uncertainty in a perceptual task:**
A) Perfect performance is impossible, and even the ideal observer will make errors  
B) Perfect performance is still possible with enough practice  
C) Only real systems make errors; ideal observers never do  
D) Uncertainty does not affect performance  

<details>
<summary><b>Answer</b></summary>

**A)** Perfect performance is impossible, and even the ideal observer will make errors

**Explanation:** The ideal observer is a theoretical system that performs optimally. Ideal performance represents the theoretical upper limit—no real system can perform better. However, if there is uncertainty in the task (e.g., ambiguous signals, noise), perfect performance is impossible even for the ideal observer, and it will make errors. Real systems typically achieve sub-ideal performance.
</details>

---

### H4. Complete
**Explain the "master map of locations" in feature integration theory and how it relates to binding. Why is attention necessary for binding features into objects?**

<details>
<summary><b>Answer</b></summary>

The **master map of locations** contains all the locations in the visual field where features have been detected during the pre-attentive stage. When attention is focused at a particular location on this map, the features currently at that position are attended to and bound together into a coherent object.

**Why attention is necessary:** Features are initially processed independently in different brain areas (e.g., colour in one area, shape in another). To create a coherent object (e.g., a red triangle), the system must combine "what" information (triangle, red) with "where" information (same spatial location). This binding requires focused attention because:

1. Features are detected automatically and in parallel, but they are not yet linked to specific objects.
2. Multiple features may be present at different locations; attention selects which location's features to bind.
3. Without attention, features may be incorrectly combined (e.g., red from one location with triangle from another).

The visual search evidence supports this: single features can be detected pre-attentively (search time doesn't increase with display size), but conjunction searches (requiring binding) are slow and scale with display size, indicating attention is needed.

**Explanation:** The master map is the spatial framework that allows attention to select which features to bind together, solving the "binding problem" of how separate feature representations become unified objects.
</details>

---

### H5. MCQ
**In the improved version of Broadbent's theory, why can people notice their names in unattended channels?**
A) Because the filter is not working properly  
B) Because Stage 2 checks stimuli against permanent memory for high-priority messages like one's name  
C) Because names are processed in Stage 1 with physical characteristics  
D) Because late selection allows all stimuli to be recognized before filtering  

<details>
<summary><b>Answer</b></summary>

**B)** Because Stage 2 checks stimuli against permanent memory for high-priority messages like one's name

**Explanation:** The improved model addresses the limitation that people notice their names even when not attending to that channel. Stage 2 checks all stimuli (even unattended ones) against a permanent memory list of high-priority messages, including danger signals and vocal patterns of one's name. This allows important information to break through the filter, even if it wasn't the focus of attention. This is why selective attention doesn't mean complete suppression—high-priority events can still be detected.
</details>

---

### H6. Complete
**Describe how the concept of "binding" relates to the "what" and "where" systems in vision. Why is spatial location critical for binding features into objects?**

<details>
<summary><b>Answer</b></summary>

**Binding** is the process of combining perceptual features (like colour and shape) into a coherent representation of a single object. Neuropsychological evidence indicates that the brain has separate "what" and "where" systems that operate in parallel:

- **"What" system:** Processes object properties (shape, colour, identity)
- **"Where" system:** Processes spatial location information

**Why spatial location is critical:** Two features are part of the same object if they occupy the same location in space and time. For example, a "green triangle" requires the co-occurrence of green (colour feature) and triangle (shape feature) at the same spatial location. To bind these features, the system must combine:
1. **What** information: "triangle" and "green" (from the what system)
2. **Where** information: "at location X" (from the where system)

Without spatial location, features could be incorrectly bound (e.g., green from one location with triangle from another). The master map of locations in feature integration theory serves this function—it tracks where features are detected, allowing attention to focus on a specific location and bind the features present there.

**Explanation:** Binding solves the problem of how separate feature representations become unified objects by using spatial location as the binding mechanism—features at the same location belong to the same object.
</details>

---

### H7. MCQ
**When perceptual enhancement fails (e.g., turning up a radio with static), it is because:**
A) The signal is too weak  
B) The perceptual system is not working properly  
C) External noise is too loud  
D) Attention amplifies both the signal and the noise, so increasing gain doesn't help  

<details>
<summary><b>Answer</b></summary>

**D)** Attention amplifies both the signal and the noise, so increasing gain doesn't help

**Explanation:** Perceptual enhancement works by increasing the gain (strength) of a stimulus. When the signal is clear, turning up the volume helps drown out external noise. However, when the signal itself contains noise (like static in a radio signal), turning up the volume amplifies both the signal and the noise equally, so perceptual enhancement is no longer effective. This is why attention helps more by reducing external noise (e.g., shutting a car window) rather than just amplifying everything.
</details>

---

## Answer Key (Quick Reference)

| ID | Answer |
|----|--------|
| E1 | B |
| E2 | Iconic memory (visual), echoic memory (auditory) |
| E3 | A |
| E4 | Any three: Focusing, Perceptual Enhancement, Binding, Sustaining Behaviour, Action Selection |
| E5 | D |
| N1 | A |
| N2 | (See explanation: perceptual enhancement) |
| N3 | C |
| N4 | (See explanation: three stages) |
| N5 | B |
| N6 | (See explanation: single feature vs conjunction search) |
| N7 | D |
| N8 | (See explanation: early vs late selection) |
| H1 | C |
| H2 | (See explanation: bottleneck vs capacity theories) |
| H3 | A |
| H4 | (See explanation: master map and binding) |
| H5 | B |
| H6 | (See explanation: what/where systems and binding) |
| H7 | D |
